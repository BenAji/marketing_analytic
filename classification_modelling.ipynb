{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5661e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#import xgboost as XGBClassifier\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6ed43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "output_dir = 'data'\n",
    "#plots_dir = 'plots'\n",
    "models_dir = 'model'\n",
    "#os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f86fd181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Classification Modeling for Response Prediction...\n",
      "Loading engineered features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Classification Modeling for Response Prediction...\")\n",
    "\n",
    "# Load the engineered features dataset\n",
    "print(\"Loading engineered features...\")\n",
    "modeling_df = pd.read_csv(f\"{output_dir}/modeling_features.csv\", nrows=20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13685f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Data for Modeling ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare data for modeling\n",
    "print(\"\\n--- Preparing Data for Modeling ---\")\n",
    "\n",
    "# Define features and target\n",
    "X = modeling_df.drop(['customer_id', 'has_responded', 'total_revenue'], axis=1)\n",
    "y = modeling_df['has_responded']\n",
    "\n",
    "# Convert features to numpy array to remove feature names\n",
    "X = X.to_numpy()\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = np.isnan(X).sum(axis=0)\n",
    "missing_cols = np.where(missing_values > 0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32387f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "class_counts = y.value_counts()\n",
    "class_percentages = class_counts / len(y) * 100\n",
    "\n",
    "# Imbalance ratio\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6244604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "106d3d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handling Missing Values with Imputation ---\n"
     ]
    }
   ],
   "source": [
    "# 2. Handle missing values with imputation\n",
    "print(\"\\n--- Handling Missing Values with Imputation ---\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81592505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- convert x_test to numpy ---\n"
     ]
    }
   ],
   "source": [
    "#  Convert test data to numpy array as well to ensure consistency\n",
    "print(\"\\n--- convert x_test to numpy ---\")\n",
    "if isinstance(X_test_imputed, pd.DataFrame):\n",
    "    X_test_imputed = X_test_imputed.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2e91e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handling Class Imbalance with SMOTE ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Handle class imbalance with SMOTE\n",
    "print(\"\\n--- Handling Class Imbalance with SMOTE ---\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80edecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Class distribution after SMOTE\n",
    "smote_class_counts = pd.Series(y_train_smote).value_counts()\n",
    "smote_class_percentages = smote_class_counts / len(y_train_smote) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9031ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define evaluation metrics\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'model': model\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f7ccba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training and Evaluating Multiple Models ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Train and evaluate multiple models\n",
    "print(\"\\n--- Training and Evaluating Multiple Models ---\")\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    #'XGBoost': XGBClassifier.XGBClassifier(scale_pos_weight=imbalance_ratio, random_state=42),\n",
    "    'SVM': SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a5672ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayoad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating Random Forest...\n",
      "Training and evaluating Gradient Boosting...\n",
      "Training and evaluating SVM...\n",
      "Training and evaluating K-Nearest Neighbors...\n",
      "Training and evaluating Naive Bayes...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and evaluating {model_name}...\")\n",
    "\n",
    "    # Store feature names before converting to numpy array\n",
    "    feature_names = list(X_train.columns)\n",
    "\n",
    "    result = evaluate_model(model, X_train_smote, y_train_smote, X_test_imputed, y_test, model_name)\n",
    "    results.append(result)\n",
    "    \n",
    "        # Set feature names for the model\n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        model.feature_names_in_ = feature_names\n",
    "        \n",
    "    # Save the model using pickle\n",
    "    # For saving individual models in the loop\n",
    "    with open(f\"{models_dir}/{model_name.lower().replace(' ', '_')}_model.pkl\", 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('f1_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71d4b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Hyperparameter Tuning ---\n",
      "Best model based on F1-score: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# 6. Hyperparameter tuning for the best model\n",
    "print(\"\\n--- Performing Hyperparameter Tuning ---\")\n",
    "\n",
    "# Identify the best model based on F1-score\n",
    "best_model_name = results_df.iloc[0]['model_name']\n",
    "print(f\"Best model based on F1-score: {best_model_name}\")\n",
    "\n",
    "# Define hyperparameter grids for each model type\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    #},\n",
    "    #'XGBoost': {\n",
    "    #    'n_estimators': [100, 200, 300],\n",
    "    #    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    #    'max_depth': [3, 5, 7],\n",
    "    #    'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto', 0.1, 1],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "036f1252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the parameter grid for the best model\n",
    "best_param_grid = param_grids[best_model_name]\n",
    "\n",
    "# Create a new instance of the best model\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    best_model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    best_model = GradientBoostingClassifier(random_state=42)\n",
    "#elif best_model_name == 'XGBoost':\n",
    "#    best_model = XGBClassifier.XGBClassifier(scale_pos_weight=imbalance_ratio, random_state=42)\n",
    "elif best_model_name == 'SVM':\n",
    "    best_model = SVC(class_weight='balanced', probability=True, random_state=42)\n",
    "elif best_model_name == 'K-Nearest Neighbors':\n",
    "    best_model = KNeighborsClassifier()\n",
    "elif best_model_name == 'Naive Bayes':\n",
    "    best_model = GaussianNB()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=best_model,\n",
    "    param_grid=best_param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_tuned_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned model\n",
    "tuned_result = evaluate_model(best_tuned_model, X_train_smote, y_train_smote, X_test_imputed, y_test, f\"{best_model_name} (Tuned)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0152cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature names for the tuned model\n",
    "if isinstance(best_tuned_model, RandomForestClassifier):\n",
    "    best_tuned_model.feature_names_in_ = feature_names\n",
    "\n",
    "# For saving the tuned model\n",
    "with open(f\"{models_dir}/{best_model_name.lower().replace(' ', '_')}_tuned_model.pkl\", 'wb') as file:\n",
    "    pickle.dump(best_tuned_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7da126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
